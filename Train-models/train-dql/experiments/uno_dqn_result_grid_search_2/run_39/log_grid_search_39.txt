=========CONFIG=========
env: uno
algorithm: dqn
seed: 42
num_episodes: 1000
num_eval_games: 100
evaluate_every: 100
log_dir: experiments/uno_dqn_result/
==========ARGS==========
replay_memory_size: 20000
replay_memory_init_size: 100
update_target_estimator_every: 1000
discount_factor: 0.98
epsilon_start: 1.0
epsilon_end: 0.05
epsilon_decay_steps: 10000
batch_size: 32
num_actions: 2
state_shape: None
train_every: 1
mlp_layers: [64, 64]
learning_rate: 5e-05
device: None
save_path: None
save_every: inf
----------------------------------------
  episode      |  0
  reward       |  0.06
----------------------------------------
----------------------------------------
  episode      |  100
  reward       |  0.18
----------------------------------------
----------------------------------------
  episode      |  200
  reward       |  -0.14
----------------------------------------
----------------------------------------
  episode      |  300
  reward       |  0.0
----------------------------------------
----------------------------------------
  episode      |  400
  reward       |  0.08
----------------------------------------
----------------------------------------
  episode      |  500
  reward       |  -0.04
----------------------------------------
----------------------------------------
  episode      |  600
  reward       |  0.18
----------------------------------------
----------------------------------------
  episode      |  700
  reward       |  -0.22
----------------------------------------
----------------------------------------
  episode      |  800
  reward       |  -0.24
----------------------------------------
----------------------------------------
  episode      |  900
  reward       |  0.22
----------------------------------------
