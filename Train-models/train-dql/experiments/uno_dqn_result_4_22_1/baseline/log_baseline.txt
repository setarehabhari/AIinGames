=========CONFIG=========
env: uno
algorithm: dqn
seed: 42
num_episodes: 5000
num_eval_games: 100
evaluate_every: 100
log_dir: experiments/uno_dqn_result_4_22_1/
==========ARGS==========
replay_memory_size: 20000
replay_memory_init_size: 100
update_target_estimator_every: 1000
discount_factor: 0.99
epsilon_start: 1.0
epsilon_end: 0.1
epsilon_decay_steps: 5000
batch_size: 32
num_actions: 2
state_shape: None
train_every: 1
mlp_layers: [64, 64]
learning_rate: 5e-05
device: cuda
save_path: None
save_every: inf
----------------------------------------
  episode      |  0
  reward       |  0.04
----------------------------------------
----------------------------------------
  episode      |  100
  reward       |  -0.16
----------------------------------------
----------------------------------------
  episode      |  200
  reward       |  0.08
----------------------------------------
----------------------------------------
  episode      |  300
  reward       |  -0.08
----------------------------------------
----------------------------------------
  episode      |  400
  reward       |  -0.04
----------------------------------------
----------------------------------------
  episode      |  500
  reward       |  -0.12
----------------------------------------
----------------------------------------
  episode      |  600
  reward       |  0.02
----------------------------------------
----------------------------------------
  episode      |  700
  reward       |  -0.02
----------------------------------------
----------------------------------------
  episode      |  800
  reward       |  0.04
----------------------------------------
----------------------------------------
  episode      |  900
  reward       |  0.0
----------------------------------------
